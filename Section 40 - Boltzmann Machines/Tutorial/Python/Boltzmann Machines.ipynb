{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boltzmann Machines\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset:- https://files.grouplens.org/datasets/movielens/ml-100k.zip, https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "\n",
    "#### Dataset For Testing:- https://grouplens.org/datasets/movielens/\n",
    "\n",
    "#### Reference Book:- [An Introduction to Restricted Boltzmann Machines](Reference/An%20Introduction%20to%20Restricted%20Boltzmann%20Machines.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machines (RBMs)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set, dtype = 'int')\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.array(test_set, dtype = 'int')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the number of users and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n",
    "nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))\n",
    "nb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data into an array with users in lines and movies in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:, 1] [data[:, 0] == id_users]\n",
    "        id_ratings = data[:, 2] [data[:, 0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data into Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torch.FloatTensor(test_set)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[training_set == 0] = -1\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Architecture of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, nv, nh): # nv = No. of Visible Nodes, nh = No. of Hidden Nodes\n",
    "        # Initializing the weights\n",
    "        self.W = torch.randn(nh, nv)\n",
    "\n",
    "        # Initializing the bias for the hidden nodes\n",
    "        self.a = torch.randn(1, nh)\n",
    "\n",
    "        # Initializing the bias for the visible nodes\n",
    "        self.b = torch.randn(1, nv)\n",
    "\n",
    "\n",
    "    # Function for returning different samples for hidden nodes\n",
    "    def sample_h(self, x): # \"x\" -> to the vector visible neurons \"v\" in the probabilities \"p\" of \"h (hidden nodes)\", given \"v (visible nodes)\"\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "\n",
    "    # Function for returning different samples for visible nodes\n",
    "    def sample_v(self, y): # \"y\" -> to the vector hidden neurons \"h\" in the probabilities \"p\" of \"v (visible nodes)\", given \"h (hidden nodes)\"\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    \n",
    "\n",
    "    # Defining the Contrastive Divergence\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        # v0 -> input vector containing the ratings of all the movies by one user\n",
    "        # vk -> visible nodes obtained after \"k\" samplings\n",
    "        # ph0 -> vector of probabilities that at the first iteration the hidden nodes = 1 given the value of \"v0\"\n",
    "        # phk -> probability of visible nodes obtained after \"k\" samplings given the value of \"vk\"\n",
    "\n",
    "        # Updating the Weight\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "\n",
    "        # Updating the bias \"b\"\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "\n",
    "        # Updating the bias \"a\"\n",
    "        self.a += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the object of RBM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of epochs\n",
    "nb_epochs = 10\n",
    "\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.  # Counter\n",
    "\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user:id_user + batch_size]\n",
    "        v0 = training_set[id_user:id_user + batch_size]\n",
    "        ph0, _ = rbm.sample_h(v0)\n",
    "\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk) # hk -> \"h\" hidden nodes obtained at the \"k\"th step of contrastive divergence\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "        \n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
    "        s += 1.\n",
    "\n",
    "    print(\"epoch: \" + str(epoch) + \" loss: \" + str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1]\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0])) # Average Distance here\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating The Boltzmann Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi guys,\n",
    "<br>&emsp;the two ways of evaluating our RBM are with the *RMSE* and the *Average Distance*.\n",
    "\n",
    "#### RMSE:\n",
    "\n",
    "* The RMSE (Root Mean Squared Error) is calculated as the root of the mean of the squared differences between the predictions and the targets.\n",
    "\n",
    "Here is the code that computes the RMSE:\n",
    "\n",
    "**Training phase:**\n",
    "\n",
    "        nb_epoch = 10\n",
    "        for epoch in range(1, nb_epoch + 1):\n",
    "            train_loss = 0\n",
    "            s = 0.\n",
    "            for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "                vk = training_set[id_user:id_user+batch_size]\n",
    "                v0 = training_set[id_user:id_user+batch_size]\n",
    "                ph0,_ = rbm.sample_h(v0)\n",
    "                for k in range(10):\n",
    "                    _,hk = rbm.sample_h(vk)\n",
    "                    _,vk = rbm.sample_v(hk)\n",
    "                    vk[v0<0] = v0[v0<0]\n",
    "                phk,_ = rbm.sample_h(vk)\n",
    "                rbm.train(v0, vk, ph0, phk)\n",
    "                train_loss += np.sqrt(torch.mean((v0[v0>=0] - vk[v0>=0])**2)) # RMSE here\n",
    "                s += 1.\n",
    "            print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "\n",
    "**Test phase:**\n",
    "\n",
    "        test_loss = 0\n",
    "        s = 0.\n",
    "        for id_user in range(nb_users):\n",
    "            v = training_set[id_user:id_user+1]\n",
    "            vt = test_set[id_user:id_user+1]\n",
    "            if len(vt[vt>=0]) > 0:\n",
    "                _,h = rbm.sample_h(v)\n",
    "                _,v = rbm.sample_v(h)\n",
    "                test_loss += np.sqrt(torch.mean((vt[vt>=0] - v[vt>=0])**2)) # RMSE here\n",
    "                s += 1.\n",
    "        print('test loss: '+str(test_loss/s))\n",
    "\n",
    "* Using the RMSE, our RBM would obtain an error around `0.46`. But be careful, although it looks similar, one must not confuse the RMSE and the Average Distance. A RMSE of `0.46` doesn’t mean that the average distance between the prediction and the ground truth is `0.46`. In random mode we would end up with a RMSE around `0.72`. An error of `0.46` corresponds to `75%` of successful prediction.\n",
    "\n",
    "#### Average Distance:\n",
    "\n",
    "* If you prefer to play with the Average Distance, I understand, it’s more intuitive. And that’s what we used in the practical tutorials to evaluate our RBM model:\n",
    "\n",
    "**Training phase:**\n",
    "\n",
    "        nb_epoch = 10\n",
    "        for epoch in range(1, nb_epoch + 1):\n",
    "            train_loss = 0\n",
    "            s = 0.\n",
    "            for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "                vk = training_set[id_user:id_user+batch_size]\n",
    "                v0 = training_set[id_user:id_user+batch_size]\n",
    "                ph0,_ = rbm.sample_h(v0)\n",
    "                for k in range(10):\n",
    "                    _,hk = rbm.sample_h(vk)\n",
    "                    _,vk = rbm.sample_v(hk)\n",
    "                    vk[v0<0] = v0[v0<0]\n",
    "                phk,_ = rbm.sample_h(vk)\n",
    "                rbm.train(v0, vk, ph0, phk)\n",
    "                train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0])) # Average Distance here\n",
    "                s += 1.\n",
    "            print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "\n",
    "**Test phase:**\n",
    "\n",
    "        test_loss = 0\n",
    "        s = 0.\n",
    "        for id_user in range(nb_users):\n",
    "            v = training_set[id_user:id_user+1]\n",
    "            vt = test_set[id_user:id_user+1]\n",
    "            if len(vt[vt>=0]) > 0:\n",
    "                _,h = rbm.sample_h(v)\n",
    "                _,v = rbm.sample_v(h)\n",
    "                test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0])) # Average Distance here\n",
    "                s += 1.\n",
    "        print('test loss: '+str(test_loss/s))\n",
    "\n",
    "* With this metric, we obtained an Average Distance of `0.24`, which is equivalent to about `75%` of correct prediction.\n",
    "\n",
    "* Hence, it works very well and there is a predictive power.\n",
    "\n",
    "* If you want to check that `0.25` corresponds to `75%` of success, you can run the following test:\n",
    "\n",
    "        import numpy as np\n",
    "        u = np.random.choice([0,1], 100000)\n",
    "        v = np.random.choice([0,1], 100000)\n",
    "        u[:50000] = v[:50000]\n",
    "        sum(u==v)/float(len(u)) # -> you get 0.75\n",
    "        np.mean(np.abs(u-v)) # -> you get 0.25\n",
    "        so 0.25 corresponds to 75% of success.\n",
    "\n",
    "*Enjoy Deep Learning!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "u = np.random.choice([0,1], 100000)\n",
    "v = np.random.choice([0,1], 100000)\n",
    "\n",
    "u[:50000] = v[:50000]\n",
    "\n",
    "print(sum(u==v)/float(len(u))) # -> you get 0.75\n",
    "\n",
    "print(np.mean(np.abs(u-v))) # -> you get 0.2489 which is approx. 0.25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
